{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267d971f",
   "metadata": {},
   "source": [
    "# ğŸ§  13:00â€“15:00 ì‘ìš© ì‹¤ìŠµ â€” NIST PDF RAG (Chroma + LCEL)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **`src/04_embeddings_chroma.py` + `src/05_rag_pipeline.py`** ë‚´ìš©ì„ í•˜ë‚˜ë¡œ í•©ì¹œ **ì‹¤ìŠµ í†µí•© ë²„ì „**ì…ë‹ˆë‹¤.  \n",
    "ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "1) í™˜ê²½ ë³€ìˆ˜/ê²½ë¡œ ì„¸íŒ…  \n",
    "2) PDF ë¡œë”© â†’ Document ëª©ë¡ ë§Œë“¤ê¸°  \n",
    "3) Chunking(í…ìŠ¤íŠ¸ ë¶„í• )  \n",
    "4) Embedding + Chroma ë²¡í„°ìŠ¤í† ì–´ ì¸ë±ì‹±(persist)  \n",
    "5) Retriever ìƒì„±  \n",
    "6) LCEL ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì¶• (`question` â†’ `answer`)  \n",
    "7) í…ŒìŠ¤íŠ¸ ì§ˆì˜ & LangSmith Trace í™•ì¸ ê°€ì´ë“œ  \n",
    "8) ğŸ§ª ììœ  ì‹¤í—˜ ì¹¸ (TODO ì…€)\n",
    "\n",
    "> âš ï¸ ë£¨íŠ¸ ê²½ë¡œì— `.env` íŒŒì¼ì´ ìˆê³ , `OPENAI_API_KEY`, `LANGCHAIN_API_KEY`, `LANGCHAIN_TRACING_V2=true`, `LANGCHAIN_PROJECT=gccare-rag-workshop` ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11a714",
   "metadata": {},
   "source": [
    "## 1) í™˜ê²½ ë³€ìˆ˜ & ê²½ë¡œ ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f89274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: /Users/sjcha/Documents/6. á„€á…¢á„‹á…µá†«á„Œá…¡á†¨á„‹á…¥á†¸ á„€á…ªá†«á„…á…µ(smilechacha)/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…©/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…© - 04 - GCá„á…¦á„‹á…¥&á„‹á…²á„‡á…µá„á…¦á„‹á…¥/202511_gccare/gccare-langchain-rag-ai\n",
      "OPENAI_API_KEY set?: True\n",
      "LANGCHAIN_API_KEY set?: True\n",
      "LANGCHAIN_TRACING_V2: true\n",
      "LANGCHAIN_PROJECT: gccare-rag-workshop\n",
      "DOCS_DIR exists?: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ë ˆí¬ ë£¨íŠ¸ ê¸°ì¤€ .env\n",
    "BASE_DIR = Path.cwd().resolve().parents[0]  # ë…¸íŠ¸ë¶ ìœ„ì¹˜ì— ë”°ë¼ ì¡°ì •í•˜ì„¸ìš”\n",
    "ENV_PATH = BASE_DIR / \".env\"\n",
    "load_dotenv(ENV_PATH)\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"OPENAI_API_KEY set?:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"LANGCHAIN_API_KEY set?:\", bool(os.getenv(\"LANGCHAIN_API_KEY\")))\n",
    "print(\"LANGCHAIN_TRACING_V2:\", os.getenv(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(\"LANGCHAIN_PROJECT:\", os.getenv(\"LANGCHAIN_PROJECT\"))\n",
    "\n",
    "DOCS_DIR = BASE_DIR / \"data\" / \"docs\"\n",
    "CHROMA_DIR = BASE_DIR / \"chroma_store\"\n",
    "print(\"DOCS_DIR exists?:\", DOCS_DIR.exists())\n",
    "CHROMA_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cf815",
   "metadata": {},
   "source": [
    "## 2) PDF ë¡œë”© â†’ Document ë§Œë“¤ê¸°\n",
    "\n",
    "- `langchain_community.document_loaders.PyPDFLoader` ì‚¬ìš©\n",
    "- ê° í˜ì´ì§€ë¥¼ `Document`ë¡œ ë§Œë“¤ê³ , `metadata['source']`ì— íŒŒì¼ëª… ê¸°ë¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7577f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pages: 139\n",
      "{'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-24T14:45:46-05:00', 'author': 'National Institute of Standards and Technology', 'keywords': 'Artificial Intelligence (AI); AI; AI RMF; AI RMF 1.0; AI systems; trustworthy and responsible AI.', 'moddate': '2025-06-04T13:01:45-04:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.24 (TeX Live 2022) kpathsea version 6.3.4', 'subject': 'As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework. The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms.', 'title': 'Artificial Intelligence Risk Management Framework (AI RMF 1.0)', 'trapped': '/False', 'source': '/Users/sjcha/Documents/6. á„€á…¢á„‹á…µá†«á„Œá…¡á†¨á„‹á…¥á†¸ á„€á…ªá†«á„…á…µ(smilechacha)/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…©/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…© - 04 - GCá„á…¦á„‹á…¥&á„‹á…²á„‡á…µá„á…¦á„‹á…¥/202511_gccare/gccare-langchain-rag-ai/data/docs/nist_ai_risk_framework.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}\n",
      "NIST AI 100-1\n",
      "Artificial Intelligence Risk Management\n",
      "Framework (AI RMF 1.0)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_all_pdfs(docs_dir: Path) -> List[Document]:\n",
    "    pdf_paths = sorted(docs_dir.glob(\"*.pdf\"))\n",
    "    docs: List[Document] = []\n",
    "    for path in pdf_paths:\n",
    "        loader = PyPDFLoader(str(path))\n",
    "        loaded = loader.load()\n",
    "        for d in loaded:\n",
    "            d.metadata.setdefault(\"source\", path.name)\n",
    "        docs.extend(loaded)\n",
    "    return docs\n",
    "\n",
    "docs = load_all_pdfs(DOCS_DIR)\n",
    "print(f\"Loaded pages: {len(docs)}\")\n",
    "if docs:\n",
    "    print(docs[0].metadata)\n",
    "    print(docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d7657",
   "metadata": {},
   "source": [
    "## 3) Chunking (í…ìŠ¤íŠ¸ ë¶„í• )\n",
    "\n",
    "- `RecursiveCharacterTextSplitter`ë¡œ ì ë‹¹í•œ í¬ê¸°ì™€ overlap ì„¤ì •\n",
    "- íŒŒë¼ë¯¸í„°ë¥¼ ë°”ê¾¸ë©° ê²°ê³¼ chunk ìˆ˜/í’ˆì§ˆ ì°¨ì´ë¥¼ ê´€ì°°í•´ ë³´ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4428d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 541\n",
      "{'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-24T14:45:46-05:00', 'author': 'National Institute of Standards and Technology', 'keywords': 'Artificial Intelligence (AI); AI; AI RMF; AI RMF 1.0; AI systems; trustworthy and responsible AI.', 'moddate': '2025-06-04T13:01:45-04:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.24 (TeX Live 2022) kpathsea version 6.3.4', 'subject': 'As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework. The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms.', 'title': 'Artificial Intelligence Risk Management Framework (AI RMF 1.0)', 'trapped': '/False', 'source': '/Users/sjcha/Documents/6. á„€á…¢á„‹á…µá†«á„Œá…¡á†¨á„‹á…¥á†¸ á„€á…ªá†«á„…á…µ(smilechacha)/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…©/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…© - 04 - GCá„á…¦á„‹á…¥&á„‹á…²á„‡á…µá„á…¦á„‹á…¥/202511_gccare/gccare-langchain-rag-ai/data/docs/nist_ai_risk_framework.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}\n",
      "NIST AI 100-1\n",
      "Artificial Intelligence Risk Management\n",
      "Framework (AI RMF 1.0)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(docs: List[Document], chunk_size=800, chunk_overlap=120) -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "chunks = split_documents(docs, chunk_size=800, chunk_overlap=120)\n",
    "print(\"Chunks:\", len(chunks))\n",
    "if chunks:\n",
    "    print(chunks[0].metadata)\n",
    "    print(chunks[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96fa4ac",
   "metadata": {},
   "source": [
    "## 4) Embedding + Chroma ì¸ë±ì‹± (persist)\n",
    "\n",
    "- OpenAI Embeddingsë¡œ ë¬¸ì„œ ì¡°ê°ì„ ë²¡í„°í™”\n",
    "- Chroma ë¡œì»¬ ë””ë ‰í† ë¦¬ì— ì €ì¥í•˜ì—¬ í›„ì† ì„¸ì…˜ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18344369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma persisted at: /Users/sjcha/Documents/6. á„€á…¢á„‹á…µá†«á„Œá…¡á†¨á„‹á…¥á†¸ á„€á…ªá†«á„…á…µ(smilechacha)/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…©/@á„†á…©á„ƒá…®á„‹á…´á„‹á…§á†«á„€á…®á„‰á…© - 04 - GCá„á…¦á„‹á…¥&á„‹á…²á„‡á…µá„á…¦á„‹á…¥/202511_gccare/gccare-langchain-rag-ai/chroma_store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jc/4z1x4d2x08v3pks_cvns5kzr0000gn/T/ipykernel_73352/595306487.py:12: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "def build_chroma_index(chunks: List[Document], db_dir: Path, collection_name=\"nist-security-docs\"):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=str(db_dir),\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    vectordb.persist()\n",
    "    return vectordb\n",
    "\n",
    "vectordb = build_chroma_index(chunks, CHROMA_DIR, collection_name=\"nist-security-docs\")\n",
    "print(\"Chroma persisted at:\", CHROMA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb0e0a",
   "metadata": {},
   "source": [
    "## 5) Retriever ìƒì„±\n",
    "\n",
    "- `vectordb.as_retriever(k=4)` í˜•íƒœë¡œ ì‚¬ìš©\n",
    "- `k` ê°’ì€ ë‹¤ì–‘í•˜ê²Œ ì‹œë„í•´ ë³´ì„¸ìš” (ì˜ˆ: 2, 4, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c8b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jc/4z1x4d2x08v3pks_cvns5kzr0000gn/T/ipykernel_73352/237766089.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  # ì¬í™•ì¸ ìš©\n",
    "from langchain_community.vectorstores import Chroma  # ì¬í™•ì¸ ìš©\n",
    "\n",
    "def get_retriever(db_dir: Path, collection_name=\"nist-security-docs\", k=4):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=str(db_dir),\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    return vectordb.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "retriever = get_retriever(CHROMA_DIR, k=4)\n",
    "print(\"Retriever ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc029a",
   "metadata": {},
   "source": [
    "## 6) LCEL ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì¶• (`question` â†’ `answer`)\n",
    "\n",
    "- `RunnableParallel`ë¡œ `{\"context\": retriever, \"question\": passthrough}` êµ¬ì„±\n",
    "- `ChatPromptTemplate`ì— Context/Question ì£¼ì…\n",
    "- `ChatOpenAI` í˜¸ì¶œ â†’ ìµœì¢… ë‹µë³€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3690109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "ë‹¹ì‹ ì€ NIST ë³´ì•ˆ/AI í”„ë ˆì„ì›Œí¬ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë°˜ë“œì‹œ ì•„ë˜ Context ì•ˆì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë©´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”.\n",
    "\n",
    "# Context\n",
    "{context}\n",
    "\n",
    "# Question\n",
    "{question}\n",
    "\"\"\".strip()\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def join_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | (lambda docs: join_docs(docs)),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "print(\"RAG chain ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bd319",
   "metadata": {},
   "source": [
    "## 7) í…ŒìŠ¤íŠ¸ ì§ˆì˜\n",
    "\n",
    "ì•„ë˜ ì˜ˆì‹œ ì§ˆë¬¸ìœ¼ë¡œ í˜¸ì¶œí•´ ë³´ê³ , LangSmithì—ì„œ Traceê°€ ì˜ ì°íˆëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "- `\"Zero Trust Architectureì˜ í•µì‹¬ ì›ì¹™ì„ 3ê°€ì§€ë¡œ ì •ë¦¬í•´ì¤˜.\"`\n",
    "- `\"NIST AI ë¦¬ìŠ¤í¬ ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ì˜ ì£¼ìš” ë‹¨ê³„ëŠ”?\"`\n",
    "- `\"ì‚¬ë‚´ ì •ì±… ë¬¸ì„œì— ì ìš© ê°€ëŠ¥í•œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ê°€ ìˆë‚˜?\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Zero Trust Architectureì˜ í•µì‹¬ ì›ì¹™ì„ 3ê°€ì§€ë¡œ ì •ë¦¬í•´ì¤˜.\",\n",
    "    \"NIST AI ë¦¬ìŠ¤í¬ ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ì˜ ì£¼ìš” ë‹¨ê³„ëŠ”?\",\n",
    "    \"ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´.\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"\\n=== Question ===\\n\", q)\n",
    "    ans = rag_chain.invoke(q)\n",
    "    try:\n",
    "        print(\"\\n--- Answer ---\\n\", ans.content)\n",
    "    except AttributeError:\n",
    "        print(\"\\n--- Answer ---\\n\", ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891d222",
   "metadata": {},
   "source": [
    "## 8) ğŸ§ª ììœ  ì‹¤í—˜ ì¹¸ (TODO)\n",
    "\n",
    "ì•„ë˜ ì…€ì— ë§ˆìŒê» ì‹¤í—˜í•´ ë³´ì„¸ìš”. ì•„ì´ë””ì–´:\n",
    "\n",
    "- `chunk_size`, `chunk_overlap`, `k` ê°’ ë°”ê¿”ë³´ê¸°\n",
    "- Promptì— \"ê·¼ê±° ë¬¸ì¥/í˜ì´ì§€ í‘œì‹œ\" ìš”êµ¬ ì¶”ê°€í•´ ë³´ê¸°\n",
    "- ì§ˆë¬¸ ìŠ¤íƒ€ì¼(ì •ì˜/ë¹„êµ/ì ˆì°¨/ìš”ì•½/í‘œí˜„ ë³€ê²½) ë°”ê¾¸ê¸°\n",
    "- `retriever` ëŒ€ì‹  `vectordb.similarity_search` ì§ì ‘ ì‚¬ìš©í•´ ë³´ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ììœ  ì‹¤í—˜ ì…€ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ììœ  ì‹¤í—˜ ì…€ 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d0b64",
   "metadata": {},
   "source": [
    "## 9) (ì„ íƒ) ì´ˆê¸°í™”/ì •ë¦¬\n",
    "\n",
    "- ì‹¤í—˜ì„ ë°˜ë³µí•˜ê³  ì‹¶ë‹¤ë©´, `chroma_store` í´ë”ë¥¼ ì§€ìš°ê³  ë‹¤ì‹œ ì¸ë±ì‹±í•´ ë³´ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸°í™” ìœ í‹¸ (ì‹¤í–‰ ì‹œ ì£¼ì˜)\n",
    "# import shutil\n",
    "# shutil.rmtree(CHROMA_DIR, ignore_errors=True)\n",
    "# CHROMA_DIR.mkdir(exist_ok=True)\n",
    "# print(\"Chroma store cleared.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e22ae",
   "metadata": {},
   "source": [
    "## 10) LangSmith Trace í™•ì¸ íŒ\n",
    "\n",
    "- í”„ë¡œì íŠ¸: `gccare-rag-workshop`\n",
    "- Run í•˜ë‚˜ë¥¼ ì—´ì–´ ë³´ë©´:\n",
    "  - `retriever` ë‹¨ê³„ì—ì„œ ì–´ë–¤ chunkë“¤ì´ ì„ íƒë˜ì—ˆëŠ”ì§€\n",
    "  - `prompt` íƒ­ì—ì„œ Context/Questionì´ ì–´ë–»ê²Œ ì£¼ì…ëëŠ”ì§€\n",
    "  - `llm` ì‘ë‹µê³¼ í† í°/ì§€ì—°ì‹œê°„ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> **ê¶Œì¥ í™œë™:** ì•ˆ ì¢‹ì•˜ë˜ ë‹µë³€ì˜ Runì„ ê³¨ë¼, ì„ íƒëœ chunk/Prompt ì§€ì‹œë¥¼ ì ê²€í•˜ê³  `k` ê°’/Promptë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gccare-langchain-rag-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

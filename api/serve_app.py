from __future__ import annotations

"""
serve_app.py
- FastAPI + LangServe ì„œë²„
- ì—”ë“œí¬ì¸íŠ¸:
  1) /rag   : NIST PDF ê¸°ë°˜ RAG (Chroma + OpenAIEmbeddings + LCEL)

í•„ìˆ˜ ì„¤ì¹˜:
  pip install -U fastapi uvicorn langserve langchain-core langchain-openai \
                 langchain-community langchain-text-splitters chromadb python-dotenv

í™˜ê²½ ë³€ìˆ˜(.env):
  OPENAI_API_KEY=sk-...
  LANGCHAIN_TRACING_V2=true
  LANGCHAIN_PROJECT=gccare-rag-workshop
  LANGCHAIN_API_KEY=ls-...
"""

import os
from glob import glob
from pathlib import Path

from dotenv import load_dotenv
from fastapi import FastAPI
from langserve import add_routes

# ===== RAG(Chroma + LCEL) =====
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# ===========================
# ê³µí†µ ì„¤ì •
# ===========================
load_dotenv()  # .env ë¡œë“œ
APP_TITLE = "GCcare NIST RAG API"
APP_VERSION = "1.2.0"

# í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ë°ì´í„° ê²½ë¡œ
HERE = Path(__file__).resolve().parent
DATA_DIR = HERE / "data" / "docs"
PERSIST_DIR = HERE / "chroma_db"
PERSIST_DIR.mkdir(parents=True, exist_ok=True)


# ===========================
# RAG (Chroma + LCEL)
# ===========================
def load_all_pdfs(data_dir: Path):
    paths = sorted(glob(str(data_dir / "*.pdf")))
    docs = []
    for p in paths:
        try:
            loader = PyPDFLoader(p)
            docs.extend(loader.load())
        except Exception as e:
            print(f"[WARN] PDF ë¡œë“œ ì‹¤íŒ¨: {p} -> {e}")
    return docs


def format_docs(docs):
    return "\n\n".join(d.page_content for d in docs)


def build_rag_chain():
    # 0) ì„ë² ë”© ë¨¼ì € ì¤€ë¹„
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 1) ë¬¸ì„œ ë¡œë“œ
    raw_docs = load_all_pdfs(DATA_DIR)

    if raw_docs:
        # PDFê°€ ìˆì„ ë•Œë§Œ ë²¡í„°ìŠ¤í† ì–´ ì¬ìƒì„±
        splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)
        splits = splitter.split_documents(raw_docs)

        if splits:
            vectordb = Chroma.from_documents(
                documents=splits,
                embedding=embeddings,
                persist_directory=str(PERSIST_DIR),
            )
        else:
            # ì´ë¡ ìƒ ê±°ì˜ ì—†ê² ì§€ë§Œ, í˜¹ì‹œë¼ë„ splitsê°€ ë¹„ë©´ ì—¬ê¸°ë¡œ
            print("[WARN] ì²­í¬ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.")
            vectordb = Chroma(
                embedding_function=embeddings,
                persist_directory=str(PERSIST_DIR),
            )
    else:
        # ğŸ“Œ ì§€ê¸ˆ ìƒí™©: PDFê°€ í•˜ë‚˜ë„ ì—†ì„ ë•Œ
        print(f"[WARN] PDFê°€ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}. ë¹ˆ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
        vectordb = Chroma(
            embedding_function=embeddings,
            persist_directory=str(PERSIST_DIR),
        )

    retriever = vectordb.as_retriever(search_kwargs={"k": 4})

    # 3) í”„ë¡¬í”„íŠ¸ & LCEL ì²´ì¸
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
        ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ë¼.
        ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ë¼.

        [ì»¨í…ìŠ¤íŠ¸]
        {context}
        """.strip()),
        ("human", "ì§ˆë¬¸: {question}")
    ])

    llm = ChatOpenAI(model="gpt-4o-mini")

    rag_chain = (
        {
            "context": retriever | format_docs,
            "question": RunnablePassthrough(),
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain


# ===========================
# FastAPI + LangServe
# ===========================
app = FastAPI(title=APP_TITLE, version=APP_VERSION)


@app.get("/health")
def health():
    return {"status": "ok"}


# RAG ë§ˆìš´íŠ¸ (ì…ë ¥: {"input": "ì§ˆë¬¸ ë¬¸ìì—´"})
rag_chain = build_rag_chain()
add_routes(app, rag_chain, path="/rag")

print("App ready: /health, /rag")
